{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning test Competition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementation\n",
    "\n",
    "### Step 1: loading the data\n",
    "\n",
    "<a href=\"https://www.kaggle.com/c/creditcardcompetitioncs6501\">https://www.kaggle.com/c/creditcardcompetitioncs6501</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Male</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>Income</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487</td>\n",
       "      <td>1</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>13.335</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>424</td>\n",
       "      <td>1</td>\n",
       "      <td>33.670000</td>\n",
       "      <td>2.165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>31.568171</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>31.670000</td>\n",
       "      <td>16.165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>631</td>\n",
       "      <td>0</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>0.290</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>34.830000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>1.165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Male        Age    Debt  Married  BankCustomer  EducationLevel  \\\n",
       "0    487     1  24.500000  13.335        2             2               0   \n",
       "1    424     1  33.670000   2.165        1             0               1   \n",
       "2    608     1  31.568171   0.040        2             2               3   \n",
       "3     61     1  31.670000  16.165        1             0               3   \n",
       "4    631     0  27.250000   0.290        1             0               9   \n",
       "..   ...   ...        ...     ...      ...           ...             ...   \n",
       "535   71     1  34.830000   4.000        1             0               3   \n",
       "536  106     1  28.750000   1.165        1             0               8   \n",
       "537  270     1  37.580000   0.000        1             0               1   \n",
       "538  435     1  19.000000   0.000        2             2               5   \n",
       "539  102     1  18.670000   5.000        1             0              10   \n",
       "\n",
       "     Ethnicity  YearsEmployed  PriorDefault  Employed  CreditScore  Citizen  \\\n",
       "0            7          0.040             0         0            0        0   \n",
       "1            7          1.500             0         0            0        1   \n",
       "2            7          4.250             0         0            0        0   \n",
       "3            7          3.000             1         1            9        0   \n",
       "4            3          0.125             0         1            1        0   \n",
       "..         ...            ...           ...       ...          ...      ...   \n",
       "535          0         12.500             1         0            0        0   \n",
       "536          7          0.500             1         0            0        2   \n",
       "537          7          0.000             0         0            0        1   \n",
       "538          2          0.000             0         1            4        0   \n",
       "539          7          0.375             1         1            2        0   \n",
       "\n",
       "     Income  Category  \n",
       "0       475         1  \n",
       "1         0         1  \n",
       "2         0         1  \n",
       "3       730         0  \n",
       "4       108         1  \n",
       "..      ...       ...  \n",
       "535       0         1  \n",
       "536       0         1  \n",
       "537       0         0  \n",
       "538       1         1  \n",
       "539      38         1  \n",
       "\n",
       "[540 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "#loading the dataset (you have first to download the datasets from Kaggle\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Male</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>31.568171</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>511</td>\n",
       "      <td>0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>47.330000</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>19.170000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>25.420000</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>534</td>\n",
       "      <td>1</td>\n",
       "      <td>31.830000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>21.830000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>650</td>\n",
       "      <td>1</td>\n",
       "      <td>48.080000</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Male        Age  Debt  Married  BankCustomer  EducationLevel  \\\n",
       "0    286     0  31.568171  1.50        1             0               5   \n",
       "1    511     0  46.000000  4.00        1             0               7   \n",
       "2    257     1  20.000000  0.00        1             0               3   \n",
       "3    336     1  47.330000  6.50        1             0               1   \n",
       "4    318     1  19.170000  0.00        2             2               9   \n",
       "..   ...   ...        ...   ...      ...           ...             ...   \n",
       "145  292     1  25.420000  0.54        1             0              12   \n",
       "146  314     1  16.250000  0.00        2             2               0   \n",
       "147  534     1  31.830000  2.50        1             0               0   \n",
       "148   18     1  21.830000  0.25        1             0               3   \n",
       "149  650     1  48.080000  3.75        1             0               6   \n",
       "\n",
       "     Ethnicity  YearsEmployed  PriorDefault  Employed  CreditScore  Citizen  \\\n",
       "0            2          0.000             0         1            2        0   \n",
       "1            4          0.000             1         0            0        0   \n",
       "2            7          0.500             0         0            0        0   \n",
       "3            7          1.000             0         0            0        0   \n",
       "4            0          0.000             0         0            0        2   \n",
       "..         ...            ...           ...       ...          ...      ...   \n",
       "145          7          0.165             0         1            1        0   \n",
       "146          7          0.250             0         0            0        0   \n",
       "147          7          7.500             1         0            0        0   \n",
       "148          3          0.665             1         0            0        0   \n",
       "149          0          1.000             0         0            0        0   \n",
       "\n",
       "     Income  \n",
       "0       105  \n",
       "1       960  \n",
       "2         0  \n",
       "3       228  \n",
       "4         1  \n",
       "..      ...  \n",
       "145     444  \n",
       "146       0  \n",
       "147       0  \n",
       "148       0  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the test  dataset\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kaggle competition\n",
    "This is a realistic situation\n",
    "1. we have a problem we aim to solve: credit card approval automation\n",
    "2. we will use ML to learn how humans address this task using a set of examples (train dataset)\n",
    "    * What is the most suitable (best) algorithm for this task?\n",
    "    * How do we measure performance?\n",
    "    * How do we select the best algorithm?\n",
    "3. Production: we will finally deliver our final solution and predict the output for test set for which we **do not know** the Class (1 approved, 0 not-approved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is the most suitable (best) algorithm for this task?\n",
    "This is a classification problem, so we should use a classifier\n",
    "The input are a mix of \n",
    "\n",
    "continuous variables:\n",
    "\n",
    "   * age, debt, YearsEmployed, Income\n",
    "   \n",
    "discrete variables (ordinal):\n",
    "\n",
    "   * EducationLevel, CreditScore\n",
    "   \n",
    "and categorical variables\n",
    "\n",
    "   * Married, BankCustomer etc.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we measure performance?\n",
    "   * Accuracy (see Evaluation tab in Kaggle)\n",
    "   \n",
    "### How do we select the best algorithm\n",
    "   * we aim to minimize the generalisation error, so via **cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPYklEQVR4nO3cf6xkZX3H8fenrGJbqaB7JXTZ9qJd0642LuSGYmxalFZxTVxMLVkSdWs2XbXYaOo/qH9of5BAUiUxsbRrIK5GBeqPsqn0ByKGaAp4UeRnqSsuZbcrexVEjZEKfvvHHOq43Lsz986dGe7D+5VM5pznPGfO99m5+7nnPnPmpKqQJLXlF6ZdgCRp9RnuktQgw12SGmS4S1KDDHdJatC6aRcAsH79+pqdnZ12GZK0ptxyyy3fqaqZxbY9KcJ9dnaW+fn5aZchSWtKkvuW2ua0jCQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNehJ8Q1VSZqm2Qs+N7Vj77/o1WN53YFn7kmekeTmJF9PcmeSv+zaT0lyU5J9Sa5M8vSu/dhufV+3fXYslUuSljTMtMwjwMur6sXAFuDsJGcAFwOXVNVvAA8BO7v+O4GHuvZLun6SpAkaGO7V88Nu9Wndo4CXA5/q2vcA53TL27p1uu1nJcmqVSxJGmioD1STHJPkVuAwcC3wTeB7VfVo1+UAsKFb3gDcD9Btfxh4ziKvuSvJfJL5hYWF0UYhSfo5Q4V7VT1WVVuAk4HTgd8c9cBVtbuq5qpqbmZm0dsRS5JWaFmXQlbV94DrgZcAxyd5/Gqbk4GD3fJBYCNAt/1ZwHdXpVpJ0lCGuVpmJsnx3fIvAn8I3E0v5F/XddsBXN0t7+3W6bZ/oapqNYuWJB3dMNe5nwTsSXIMvV8GV1XVPye5C7giyd8AXwMu6/pfBnwsyT7gQWD7GOqWJB3FwHCvqtuAUxdpv5fe/PuR7T8G/nhVqpMkrYi3H5CkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBg0M9yQbk1yf5K4kdyZ5e9f+viQHk9zaPbb27fOuJPuS3JPkleMcgCTpidYN0edR4J1V9dUkxwG3JLm223ZJVf1tf+ckm4HtwAuBXwU+n+QFVfXYahYuSVrawDP3qjpUVV/tln8A3A1sOMou24ArquqRqvoWsA84fTWKlSQNZ1lz7klmgVOBm7qmtyW5LcnlSU7o2jYA9/ftdoBFfhkk2ZVkPsn8wsLCsguXJC1t6HBP8kzg08A7qur7wKXA84EtwCHg/cs5cFXtrqq5qpqbmZlZzq6SpAGGCvckT6MX7B+vqs8AVNUDVfVYVf0U+DA/m3o5CGzs2/3krk2SNCHDXC0T4DLg7qr6QF/7SX3dXgvc0S3vBbYnOTbJKcAm4ObVK1mSNMgwV8u8FHgDcHuSW7u2dwPnJdkCFLAfeDNAVd2Z5CrgLnpX2pzvlTKSNFkDw72qvgRkkU3XHGWfC4ELR6hLkjQCv6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGjTMde5ParMXfG5qx95/0aundmxJOhrP3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWhguCfZmOT6JHcluTPJ27v2Zye5Nsk3uucTuvYk+WCSfUluS3LauAchSfp5w5y5Pwq8s6o2A2cA5yfZDFwAXFdVm4DrunWAVwGbuscu4NJVr1qSdFQDw72qDlXVV7vlHwB3AxuAbcCertse4JxueRvw0eq5ETg+yUmrXrkkaUnLmnNPMgucCtwEnFhVh7pN3wZO7JY3APf37XagazvytXYlmU8yv7CwsMyyJUlHM3S4J3km8GngHVX1/f5tVVVALefAVbW7quaqam5mZmY5u0qSBhgq3JM8jV6wf7yqPtM1P/D4dEv3fLhrPwhs7Nv95K5NkjQhw1wtE+Ay4O6q+kDfpr3Ajm55B3B1X/sbu6tmzgAe7pu+kSRNwLoh+rwUeANwe5Jbu7Z3AxcBVyXZCdwHnNttuwbYCuwDfgS8aVUrliQNNDDcq+pLQJbYfNYi/Qs4f8S6JEkj8BuqktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBg0M9ySXJzmc5I6+tvclOZjk1u6xtW/bu5LsS3JPkleOq3BJ0tKGOXP/CHD2Iu2XVNWW7nENQJLNwHbghd0+f5fkmNUqVpI0nIHhXlU3AA8O+XrbgCuq6pGq+hawDzh9hPokSSswypz725Lc1k3bnNC1bQDu7+tzoGuTJE3QSsP9UuD5wBbgEPD+5b5Akl1J5pPMLywsrLAMSdJiVhTuVfVAVT1WVT8FPszPpl4OAhv7up7ctS32Gruraq6q5mZmZlZShiRpCSsK9yQn9a2+Fnj8Spq9wPYkxyY5BdgE3DxaiZKk5Vo3qEOSTwJnAuuTHADeC5yZZAtQwH7gzQBVdWeSq4C7gEeB86vqsfGULklaysBwr6rzFmm+7Cj9LwQuHKUoSdJo/IaqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVoYLgnuTzJ4SR39LU9O8m1Sb7RPZ/QtSfJB5PsS3JbktPGWbwkaXHDnLl/BDj7iLYLgOuqahNwXbcO8CpgU/fYBVy6OmVKkpZjYLhX1Q3Ag0c0bwP2dMt7gHP62j9aPTcCxyc5abWKlSQNZ6Vz7idW1aFu+dvAid3yBuD+vn4HurYnSLIryXyS+YWFhRWWIUlazMgfqFZVAbWC/XZX1VxVzc3MzIxahiSpz0rD/YHHp1u658Nd+0FgY1+/k7s2SdIErTTc9wI7uuUdwNV97W/srpo5A3i4b/pGkjQh6wZ1SPJJ4ExgfZIDwHuBi4CrkuwE7gPO7bpfA2wF9gE/At40hpolSQMMDPeqOm+JTWct0reA80ctSpI0Gr+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNWjfKzkn2Az8AHgMeraq5JM8GrgRmgf3AuVX10GhlSpKWYzXO3F9WVVuqaq5bvwC4rqo2Add165KkCRrHtMw2YE+3vAc4ZwzHkCQdxajhXsC/J7klya6u7cSqOtQtfxs4cbEdk+xKMp9kfmFhYcQyJEn9RppzB363qg4meS5wbZL/7N9YVZWkFtuxqnYDuwHm5uYW7SNJWpmRztyr6mD3fBj4LHA68ECSkwC658OjFilJWp4Vh3uSX05y3OPLwCuAO4C9wI6u2w7g6lGLlCQtzyjTMicCn03y+Ot8oqr+NclXgKuS7ATuA84dvUxJ0nKsONyr6l7gxYu0fxc4a5SiJEmj8RuqktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgsYV7krOT3JNkX5ILxnUcSdITjSXckxwDfAh4FbAZOC/J5nEcS5L0ROM6cz8d2FdV91bV/wJXANvGdCxJ0hHWjel1NwD3960fAH6nv0OSXcCubvWHSe5Z4bHWA99Z4b4jycXTOCowxTFPkWN+anjKjTkXjzTmX19qw7jCfaCq2g3sHvV1ksxX1dwqlLRmOOanBsf81DCuMY9rWuYgsLFv/eSuTZI0AeMK968Am5KckuTpwHZg75iOJUk6wlimZarq0SRvA/4NOAa4vKruHMexWIWpnTXIMT81OOanhrGMOVU1jteVJE2R31CVpAYZ7pLUoDUT7oNuZ5Dk2CRXdttvSjI7+SpX1xBj/oskdyW5Lcl1SZa85nWtGPa2FUn+KEklWfOXzQ0z5iTndu/1nUk+MekaV9sQP9u/luT6JF/rfr63TqPO1ZLk8iSHk9yxxPYk+WD373FbktNGPmhVPekf9D6U/SbwPODpwNeBzUf0+TPg77vl7cCV0657AmN+GfBL3fJbnwpj7vodB9wA3AjMTbvuCbzPm4CvASd068+ddt0TGPNu4K3d8mZg/7TrHnHMvwecBtyxxPatwL8AAc4Abhr1mGvlzH2Y2xlsA/Z0y58CzkqSCda42gaOuaqur6ofdas30vs+wVo27G0r/hq4GPjxJIsbk2HG/KfAh6rqIYCqOjzhGlfbMGMu4Fe65WcB/zPB+lZdVd0APHiULtuAj1bPjcDxSU4a5ZhrJdwXu53BhqX6VNWjwMPAcyZS3XgMM+Z+O+n95l/LBo65+3N1Y1V9bpKFjdEw7/MLgBck+XKSG5OcPbHqxmOYMb8PeH2SA8A1wJ9PprSpWe7/94GmdvsBrZ4krwfmgN+fdi3jlOQXgA8AfzLlUiZtHb2pmTPp/XV2Q5LfrqrvTbWq8ToP+EhVvT/JS4CPJXlRVf102oWtFWvlzH2Y2xn8f58k6+j9KffdiVQ3HkPdwiHJHwDvAV5TVY9MqLZxGTTm44AXAV9Msp/e3OTeNf6h6jDv8wFgb1X9pKq+BfwXvbBfq4YZ807gKoCq+g/gGfRuKtaqVb9ly1oJ92FuZ7AX2NEtvw74QnWfVKxRA8ec5FTgH+gF+1qfh4UBY66qh6tqfVXNVtUsvc8ZXlNV89Mpd1UM87P9T/TO2kmynt40zb2TLHKVDTPm/wbOAkjyW/TCfWGiVU7WXuCN3VUzZwAPV9WhkV5x2p8iL+PT5q30zli+Cbyna/srev+5offm/yOwD7gZeN60a57AmD8PPADc2j32TrvmcY/5iL5fZI1fLTPk+xx601F3AbcD26dd8wTGvBn4Mr0raW4FXjHtmkcc7yeBQ8BP6P0lthN4C/CWvvf4Q92/x+2r8XPt7QckqUFrZVpGkrQMhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0P8BKrRmYd6aOZ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train.iloc[:,-1].values);## class frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority class is $1$, this is useful because we can use the accuracy of the majority class\n",
    "classifier as baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5685185185185185"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(df_train.iloc[:,-1].values==1)[0])/len(df_train.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 2: 10-fold Cross-validation\n",
    "To minimize the generalization error, we evaluate the performance of our ML solution via cross-validation.\n",
    "\n",
    "**Rule-of-thumb:** we use 10-fold CV because it works well in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "../CV.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "image/png": {
       "width": 1100
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"../CV.png\",width=1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#We convert data into numpy arrays\n",
    "id_person=df_train.iloc[:,0].values # column of customer id\n",
    "X = df_train.iloc[:,1:-1].values # column of the inputs\n",
    "y = df_train.iloc[:,-1].values # column of the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold CV loop\n",
    "This is a generic 10-fold CV loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-249662072838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# (D) Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mAccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average 10-fold cross-validation accuracy=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "Accuracy=[]\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    #print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "    X_train, X_test, y_train, y_test =X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "    #(A) data pre-processing (e.g., discretisation, scaling)\n",
    "    # ... discretisation, scaling\n",
    "    \n",
    "    #(B)  ML algorithm fitting\n",
    "\n",
    "    \n",
    "    # (C) Prediction\n",
    "\n",
    "    \n",
    "    # (D) Score \n",
    "    Accuracy.append(accuracy_score(y_test,y_test_pred))\n",
    "    \n",
    "print(\"Average 10-fold cross-validation accuracy=\",np.mean(np.array(Accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithm 1\n",
    "we use logistic regression, by assuming that all the inputs are continuous.\n",
    "We can do it because categorical variables are numeric in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 10-fold cross-validation accuracy= 0.8407407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/shravan/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "k_fold = KFold(n_splits=10,  shuffle=True, random_state=42)\n",
    "Accuracy=[]\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    #print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "    X_train, X_test, y_train, y_test =X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "    #(A) data pre-processing (e.g., discretisation, scaling)\n",
    "    # ... discretisation, scaling    \n",
    "    #(B)  ML algorithm fitting\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # (C) Prediction\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "    # (D) Score \n",
    "    Accuracy.append(accuracy_score(y_test,y_test_pred))\n",
    "    \n",
    "print(\"Average 10-fold cross-validation accuracy=\",np.mean(np.array(Accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note all these warnings. To fit a logistic regression problem, we use a numerical optimisation.\n",
    "\n",
    "This can lead to convergence problem, that is the algorithm stops before reaching the optimal value of the parameters\n",
    "of the logistic regression model.\n",
    "\n",
    "To reduce the effects of this problem, a **rule-of-thumb** is to scale the inputs so that all the inputs\n",
    "vary between -3 and 3 (approximatively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original [  1.     24.5    13.335   2.      2.      0.      7.      0.04    0.\n",
      "   0.      0.      0.    475.   ]\n",
      "\n",
      " Transformed [ 0.65529517 -0.61724287  1.80848632  1.72741469  1.73443163 -1.33003915\n",
      "  0.72945123 -0.7020807  -1.03348203 -0.87594105 -0.48693351 -0.31285135\n",
      " -0.08416884]\n",
      "\n",
      " What StandardScaler really does: [ 0.65529517 -0.61724287  1.80848632  1.72741469  1.73443163 -1.33003915\n",
      "  0.72945123 -0.7020807  -1.03348203 -0.87594105 -0.48693351 -0.31285135\n",
      " -0.08416884]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "scalerX.fit(X_train)\n",
    "X_train_n = scalerX.transform(X_train)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"Original\", X_train[0,:])\n",
    "print(\"\\n Transformed\", X_train_n[0,:])\n",
    "print(\"\\n What StandardScaler really does:\", ((X_train-np.mean(X_train,axis=0))/np.std(X_train,axis=0))[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improving logistic regression via scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 10-fold cross-validation accuracy= 0.8703703703703705\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=10,  shuffle=True, random_state=42)\n",
    "Accuracy=[]\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    #print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "    X_train, X_test, y_train, y_test =X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "    #(A) data pre-processing \n",
    "    scalerX = StandardScaler()\n",
    "    scalerX.fit(X_train)\n",
    "    X_train_n = scalerX.transform(X_train)\n",
    "    X_test_n  = scalerX.transform(X_test )\n",
    "    \n",
    "    #(B)  ML algorithm fitting\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs', C=1)\n",
    "    clf.fit(X_train_n, y_train)    \n",
    "    # (C) Prediction\n",
    "    y_test_pred = clf.predict(X_test_n)    \n",
    "    # (D) Score \n",
    "    Accuracy.append(accuracy_score(y_test,y_test_pred))\n",
    "    \n",
    "print(\"Average 10-fold cross-validation accuracy=\",np.mean(np.array(Accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We obtained a better performance and no-warnings anymore. \n",
    "\n",
    "Note the instruction\n",
    "\n",
    "`X_test_n  = scalerX.transform(X_test )`\n",
    "\n",
    "that is we transform the test set using the scalerX we fitted with the training dataset. \n",
    "In this way, the test dataset is always independent to the training dataset and this allows us to avoid overfitting. \n",
    "\n",
    "**Rules-of-thumb:** anytime in sklearn you use a function that does `fit`, then you must only apply that function to the training dataset only. Otherwise you can risk overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Algorithm 1: production step\n",
    "Now that we are happy with algorithm 1, we can move to the \"production\" phase when we really use our ML solution to predict unseen data (the test set).\n",
    "\n",
    "First, we take our best Algorithm and train it with all the training data. \n",
    "\n",
    "Second, we compute the prediction on the test set\n",
    "\n",
    "Third, we build the solution file that needs to be uploaded in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,  31.56817109,   1.5       , ...,   2.        ,\n",
       "          0.        , 105.        ],\n",
       "       [  0.        ,  46.        ,   4.        , ...,   0.        ,\n",
       "          0.        , 960.        ],\n",
       "       [  1.        ,  20.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       ...,\n",
       "       [  1.        ,  31.83      ,   2.5       , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  1.        ,  21.83      ,   0.25      , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  1.        ,  48.08      ,   3.75      , ...,   0.        ,\n",
       "          0.        ,   2.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we use all train data:\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "#We convert test data into numpy arrays\n",
    "id_person = df_test.iloc[:,0].values # column of customer id\n",
    "X_test_final = df_test.iloc[:,1:].values # column of the inputs\n",
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scalerX = StandardScaler()\n",
    "scalerX.fit(X_train)\n",
    "X_train_n = scalerX.transform(X_train)\n",
    "X_test_n  = scalerX.transform(X_test_final )\n",
    "\n",
    "#(B)  ML algorithm fitting\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "clf.fit(X_train_n, y_train)\n",
    "\n",
    "# (C) Prediction\n",
    "y_test_pred = clf.predict(X_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Category\n",
       "0    286         1\n",
       "1    511         0\n",
       "2    257         1\n",
       "3    336         1\n",
       "4    318         1\n",
       "5    211         0\n",
       "6    624         1\n",
       "7    176         0\n",
       "8    462         1\n",
       "9    256         1\n",
       "10   662         1\n",
       "11   165         0\n",
       "12   621         1\n",
       "13    78         0\n",
       "14   676         1\n",
       "15   497         0\n",
       "16   681         1\n",
       "17   294         1\n",
       "18   645         1\n",
       "19   396         1\n",
       "20   355         1\n",
       "21   334         1\n",
       "22   289         1\n",
       "23   572         0\n",
       "24   281         1\n",
       "25   327         1\n",
       "26   250         0\n",
       "27    54         0\n",
       "28   652         1\n",
       "29   335         1\n",
       "..   ...       ...\n",
       "120  341         1\n",
       "121  361         1\n",
       "122  213         0\n",
       "123  686         1\n",
       "124  669         1\n",
       "125   86         0\n",
       "126  354         1\n",
       "127  611         1\n",
       "128  556         0\n",
       "129   41         0\n",
       "130  108         0\n",
       "131  639         1\n",
       "132   56         0\n",
       "133  333         1\n",
       "134  507         0\n",
       "135   24         0\n",
       "136  158         0\n",
       "137  518         0\n",
       "138  278         1\n",
       "139  110         0\n",
       "140   82         0\n",
       "141   51         0\n",
       "142  218         0\n",
       "143  552         0\n",
       "144  446         1\n",
       "145  292         1\n",
       "146  314         1\n",
       "147  534         0\n",
       "148   18         0\n",
       "149  650         1\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we format the prediction in the right-format for Kaggle and save it into a csv file\n",
    "Prediction = pd.DataFrame()\n",
    "Prediction.insert(0, 'Id', id_person.astype(int))\n",
    "Prediction.insert(1, 'Category', y_test_pred.astype(int))\n",
    "Prediction.to_csv(\"Prediction_logistic.csv\", index=False)\n",
    "Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ideas for improving\n",
    "1. Try  MultinomialNB with discretisation of continuous features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 10-fold cross-validation accuracy= 0.861111111111111\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=10,  shuffle=True, random_state=42)\n",
    "Accuracy=[]\n",
    "for train_indices, test_indices in k_fold.split(X):\n",
    "    #print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "    X_train, X_test, y_train, y_test =X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "    #(A) data pre-processing \n",
    "    scalerX = StandardScaler()\n",
    "    scalerX.fit(X_train)\n",
    "    X_train_n = scalerX.transform(X_train)\n",
    "    X_test_n  = scalerX.transform(X_test )\n",
    "    \n",
    "    #(B)  ML algorithm fitting\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(3,2),max_iter=500000,activation=\"logistic\",solver=\"lbfgs\", random_state=42)\n",
    "    clf.fit(X_train_n, y_train)    \n",
    "    # (C) Prediction\n",
    "    y_test_pred = clf.predict(X_test_n)    \n",
    "    # (D) Score \n",
    "    Accuracy.append(accuracy_score(y_test,y_test_pred))\n",
    "    \n",
    "print(\"Average 10-fold cross-validation accuracy=\",np.mean(np.array(Accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Classifiers\n",
    "Classifiers that accept continuous inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianNB is very similar to MultinomialNB but for continuous inputs)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "\n",
    "#Discriminat Analysis (it is a Bayesian classifier as MultinomialNB but for continuous inputs)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "#SVM (similar to logistic regression/neural networks)\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear') #linear SVM\n",
    "clf = svm.SVC(kernel='poly',degree=3) #polynomial degree 3 SVM\n",
    "clf = svm.SVC(kernel='rbf') # similar to a neural network\n",
    "\n",
    "#One layer Neural Network with 5 hidden units\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(5,), max_iter=300000,activation=\"logistic\",solver=\"lbfgs\")\n",
    "\n",
    "#Deep Neural Network with 5,4,3 hidden units\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(5,4,3), max_iter=300000,activation=\"logistic\",solver=\"lbfgs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers that accept categorical inputs\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    " clf = MultinomialNB()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " All these classifiers have either parameters (e.g., degree=3, hidden_layer_sizes=(5,))\n",
    "or smoothing parameters (like alpha in MultinomialNB) that you can optimize via 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
